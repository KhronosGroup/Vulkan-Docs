// Copyright 2015-2025 The Khronos Group Inc.
// Copyright (c) 2020-2021 NVIDIA Corporation
// SPDX-License-Identifier: CC-BY-4.0

[[dispatch]]
= Dispatching Commands

The _dispatching commands_ described in this chapter provoke work in a
compute pipeline.
Dispatching commands are recorded into a command buffer and when executed by
a queue, will produce work which executes according to the bound compute
pipeline.
A compute pipeline must: be bound to a command buffer before any dispatching
commands are recorded in that command buffer.

[open,refpage='vkCmdDispatch',desc='Dispatch compute work items',type='protos']
--
:refpage: vkCmdDispatch

To record a dispatch, call:

include::{generated}/api/protos/vkCmdDispatch.adoc[]

  * pname:commandBuffer is the command buffer into which the command will be
    recorded.
  * pname:groupCountX is the number of local workgroups to dispatch in the X
    dimension.
  * pname:groupCountY is the number of local workgroups to dispatch in the Y
    dimension.
  * pname:groupCountZ is the number of local workgroups to dispatch in the Z
    dimension.

When the command is executed, a global workgroup consisting of
[eq]#pname:groupCountX {times} pname:groupCountY {times} pname:groupCountZ#
local workgroups is assembled.

.Valid Usage
****
include::{chapters}/commonvalidity/dispatch_common.adoc[]
include::{chapters}/commonvalidity/draw_dispatch_nonindirect_common.adoc[]
  * [[VUID-vkCmdDispatch-groupCountX-00386]]
    pname:groupCountX must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[0]
  * [[VUID-vkCmdDispatch-groupCountY-00387]]
    pname:groupCountY must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[1]
  * [[VUID-vkCmdDispatch-groupCountZ-00388]]
    pname:groupCountZ must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[2]
****

include::{generated}/validity/protos/vkCmdDispatch.adoc[]
--

[open,refpage='vkCmdDispatchIndirect',desc='Dispatch compute work items with indirect parameters',type='protos']
--
:refpage: vkCmdDispatchIndirect

To record an indirect dispatching command, call:

include::{generated}/api/protos/vkCmdDispatchIndirect.adoc[]

  * pname:commandBuffer is the command buffer into which the command will be
    recorded.
  * pname:buffer is the buffer containing dispatch parameters.
  * pname:offset is the byte offset into pname:buffer where parameters
    begin.

fname:vkCmdDispatchIndirect behaves similarly to flink:vkCmdDispatch except
that the parameters are read by the device from a buffer during execution.
The parameters of the dispatch are encoded in a
slink:VkDispatchIndirectCommand structure taken from pname:buffer starting
at pname:offset.

.Valid Usage
****
include::{chapters}/commonvalidity/dispatch_common.adoc[]
include::{chapters}/commonvalidity/draw_dispatch_indirect_common.adoc[]
  * [[VUID-vkCmdDispatchIndirect-offset-00407]]
    The sum of pname:offset and the size of sname:VkDispatchIndirectCommand
    must: be less than or equal to the size of pname:buffer
****

include::{generated}/validity/protos/vkCmdDispatchIndirect.adoc[]
--

[open,refpage='VkDispatchIndirectCommand',desc='Structure specifying an indirect dispatching command',type='structs',xrefs='vkCmdDispatchIndirect']
--
The sname:VkDispatchIndirectCommand structure is defined as:

include::{generated}/api/structs/VkDispatchIndirectCommand.adoc[]

  * pname:x is the number of local workgroups to dispatch in the X
    dimension.
  * pname:y is the number of local workgroups to dispatch in the Y
    dimension.
  * pname:z is the number of local workgroups to dispatch in the Z
    dimension.

The members of sname:VkDispatchIndirectCommand have the same meaning as the
corresponding parameters of flink:vkCmdDispatch.

.Valid Usage
****
  * [[VUID-VkDispatchIndirectCommand-x-00417]]
    pname:x must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[0]
  * [[VUID-VkDispatchIndirectCommand-y-00418]]
    pname:y must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[1]
  * [[VUID-VkDispatchIndirectCommand-z-00419]]
    pname:z must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[2]
****

include::{generated}/validity/structs/VkDispatchIndirectCommand.adoc[]
--

ifdef::VK_COMPUTE_VERSION_1_1,VK_KHR_device_group[]
[open,refpage='vkCmdDispatchBase',desc='Dispatch compute work items with non-zero base values for the workgroup IDs',type='protos']
--
:refpage: vkCmdDispatchBase

To record a dispatch using non-zero base values for the components of
code:WorkgroupId, call:

ifdef::VK_COMPUTE_VERSION_1_1[]
include::{generated}/api/protos/vkCmdDispatchBase.adoc[]
endif::VK_COMPUTE_VERSION_1_1[]

ifdef::VK_KHR_device_group[]
include::{generated}/api/protos/vkCmdDispatchBaseKHR.adoc[]
endif::VK_KHR_device_group[]

  * pname:commandBuffer is the command buffer into which the command will be
    recorded.
  * pname:baseGroupX is the start value for the X component of
    code:WorkgroupId.
  * pname:baseGroupY is the start value for the Y component of
    code:WorkgroupId.
  * pname:baseGroupZ is the start value for the Z component of
    code:WorkgroupId.
  * pname:groupCountX is the number of local workgroups to dispatch in the X
    dimension.
  * pname:groupCountY is the number of local workgroups to dispatch in the Y
    dimension.
  * pname:groupCountZ is the number of local workgroups to dispatch in the Z
    dimension.

When the command is executed, a global workgroup consisting of
[eq]#pname:groupCountX {times} pname:groupCountY {times} pname:groupCountZ#
local workgroups is assembled, with code:WorkgroupId values ranging from
[eq]#[ptext:baseGroup*, ptext:baseGroup* {plus} ptext:groupCount*)# in each
component.
flink:vkCmdDispatch is equivalent to
`vkCmdDispatchBase(0,0,0,groupCountX,groupCountY,groupCountZ)`.

.Valid Usage
****
include::{chapters}/commonvalidity/dispatch_common.adoc[]
include::{chapters}/commonvalidity/draw_dispatch_nonindirect_common.adoc[]
  * [[VUID-vkCmdDispatchBase-baseGroupX-00421]]
    pname:baseGroupX must: be less than
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[0]
  * [[VUID-vkCmdDispatchBase-baseGroupX-00422]]
    pname:baseGroupY must: be less than
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[1]
  * [[VUID-vkCmdDispatchBase-baseGroupZ-00423]]
    pname:baseGroupZ must: be less than
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[2]
  * [[VUID-vkCmdDispatchBase-groupCountX-00424]]
    pname:groupCountX must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[0] minus
    pname:baseGroupX
  * [[VUID-vkCmdDispatchBase-groupCountY-00425]]
    pname:groupCountY must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[1] minus
    pname:baseGroupY
  * [[VUID-vkCmdDispatchBase-groupCountZ-00426]]
    pname:groupCountZ must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[2] minus
    pname:baseGroupZ
  * [[VUID-vkCmdDispatchBase-baseGroupX-00427]]
    If any of pname:baseGroupX, pname:baseGroupY, or pname:baseGroupZ are
    not zero, then the bound compute pipeline must: have been created with
    the ename:VK_PIPELINE_CREATE_DISPATCH_BASE_BIT flag
ifdef::VK_EXT_shader_object[]
    or the bound compute shader object must: have been created with the
    ename:VK_SHADER_CREATE_DISPATCH_BASE_BIT_EXT flag
endif::VK_EXT_shader_object[]
****

include::{generated}/validity/protos/vkCmdDispatchBase.adoc[]
--
endif::VK_COMPUTE_VERSION_1_1,VK_KHR_device_group[]

ifdef::VK_QCOM_tile_shading[]
[open,refpage='vkCmdDispatchTileQCOM',desc='Dispatch per-tile work items',type='protos']
--
:refpage: vkCmdDispatchTileQCOM

To record an area-based dispatch, call:

include::{generated}/api/protos/vkCmdDispatchTileQCOM.adoc[]

  * pname:commandBuffer is the command buffer into which the command will be
    recorded.
  * pname:pDispatchTileInfo is a pointer to a slink:VkDispatchTileInfoQCOM
    structure containing information about the area-based dispatch.

This command operates in the <<renderpass-per-tile-execution-model,per-tile
execution model>>, invoking a separate dispatch for each _covered tile_.
The global workgroup count and local workgroup size of each dispatch are
defined by the implementation to efficiently iterate over a uniform grid of
pixel blocks within the area of its _active tile_.

Each shader invocation operates on a single pixel block and its size is
determined by the shader's tiling rate, which must: be defined by shaders
executed by this command.
The code:TileShadingRateQCOM execution mode operand defines the shader's
tiling rate.
Its pname:x and pname:y must: be a power of two and less than or equal to
the <<limits-maxTileShadingRate,maxTileShadingRate>> limit.
Its pname:z must: be less than or equal to the active tile's depth as
reported by apiext:VK_QCOM_tile_properties, and
[eq]#slink:VkTilePropertiesQCOM.tileSize.z %
code:TileShadingRateQCOM::pname:z# must: equal `0`.

The start location of the shader invocation's pixel block is
[eq]#vec3(code:TileOffsetQCOM, 0) + (code:GlobalInvocationId *
code:TileShadingRateQCOM)#

Shader invocations can: perform tile attachment load/store operations at any
location within the _active tile_, but the most efficient access may: be
limited to fragment locations within and local to the shader invocation's
pixel block.

.Valid Usage
****
include::{chapters}/commonvalidity/dispatch_common.adoc[]
include::{chapters}/commonvalidity/draw_dispatch_nonindirect_common.adoc[]
  * [[VUID-vkCmdDispatchTileQCOM-None-10668]]
    When this command is recorded
    <<renderpass-per-tile-execution-model,per-tile execution model>> must:
    be enabled
  * [[VUID-vkCmdDispatchTileQCOM-None-10669]]
    The <<features-tileShadingDispatchTile,tileShadingDispatchTile>> must:
    enabled
****

include::{generated}/validity/protos/vkCmdDispatchTileQCOM.adoc[]
--

[open,refpage='VkDispatchTileInfoQCOM',desc='Structure specifying dispatch tile info',type='structs']
--
The sname:VkDispatchTileInfoQCOM structure is defined as:

include::{generated}/api/structs/VkDispatchTileInfoQCOM.adoc[]

  * pname:sType is a elink:VkStructureType value identifying this structure.
  * pname:pNext is `NULL` or a pointer to a structure extending this
    structure.

include::{generated}/validity/structs/VkDispatchTileInfoQCOM.adoc[]
--
endif::VK_QCOM_tile_shading[]

ifdef::VK_HUAWEI_subpass_shading[]
[open,refpage='vkCmdSubpassShadingHUAWEI',desc='Dispatch compute work items',type='protos']
--
:refpage: vkCmdSubpassShadingHUAWEI

A subpass shading dispatches a compute pipeline work with the work dimension
of render area of the calling subpass and work groups are partitioned by
specified work group size.
Subpass operations like code:subpassLoad are allowed to be used.

To record a subpass shading, call:

include::{generated}/api/protos/vkCmdSubpassShadingHUAWEI.adoc[]

  * pname:commandBuffer is the command buffer into which the command will be
    recorded.

When the command is executed, a global workgroup consisting of ceil (render
area size / local workgroup size) local workgroups is assembled.

.Valid Usage
****
include::{chapters}/commonvalidity/draw_dispatch_common.adoc[]
  * [[VUID-vkCmdSubpassShadingHUAWEI-None-04931]]
    This command must: be called in a subpass with bind point
    ename:VK_PIPELINE_BIND_POINT_SUBPASS_SHADING_HUAWEI.
    No draw commands can be called in the same subpass.
    Only one flink:vkCmdSubpassShadingHUAWEI command can be called in a
    subpass
****

include::{generated}/validity/protos/vkCmdSubpassShadingHUAWEI.adoc[]
--
endif::VK_HUAWEI_subpass_shading[]


ifdef::VK_NV_cuda_kernel_launch[]
[[cudadispatch]]
== Dispatch Command for CUDA PTX Kernels

Compute kernels can: be provided in SPIR-V or PTX code.
When using PTX kernels the dispatch mechanism is different than with regular
compute pipelines.

The way to create a PTX assembly file is beyond the scope of this
documentation.
For mode information, please refer to the CUDA toolkit documentation at
https://docs.nvidia.com/cuda/.

Prior to using this command, you must: initialize a CUDA module, and create
a function handle that will serve as the entry point of the kernel to
dispatch.
See <<cuda-modules, CUDA Modules>>.

The dispatching of a CUDA kernel is recorded into a command buffer, and when
executed by a queue submit, will produce work which executes according to
the bound compute pipeline.

[open,refpage='vkCmdCudaLaunchKernelNV',desc='Dispatch compute work items',type='protos']
--
:refpage: vkCmdCudaLaunchKernelNV

To record a CUDA kernel launch, call:

include::{generated}/api/protos/vkCmdCudaLaunchKernelNV.adoc[]

  * pname:commandBuffer is the command buffer into which the command will be
    recorded.
  * pname:pLaunchInfo is a pointer to a slink:VkCudaLaunchInfoNV structure
    in which the grid (similar to workgroup) dimension, function handle and
    related arguments are defined.

When the command is executed, a global workgroup consisting of
[eq]#pname:gridDimX {times} pname:gridDimY {times} pname:gridDimZ# local
workgroups is assembled.

include::{generated}/validity/protos/vkCmdCudaLaunchKernelNV.adoc[]
--


[[cudadispatch_info]]
=== Passing Dispatch Parameters and Arguments

[open,refpage='VkCudaLaunchInfoNV',desc='Structure specifying the parameters to launch a CUDA kernel',type='structs']
--
The sname:VkCudaLaunchInfoNV structure is very close to the parameters of
the CUDA-Driver function
link:++https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html#group__CUDA__EXEC_1gb8f3dc3031b40da29d5f9a7139e52e15++[cuLaunchKernel]
documented in section
link:++https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html#group__CUDA__EXEC++[6.19
Execution Control] of CUDA Driver API.

The structure is defined as:

include::{generated}/api/structs/VkCudaLaunchInfoNV.adoc[]

  * pname:sType is a elink:VkStructureType value identifying this structure.
  * pname:pNext is `NULL` or a pointer to a structure extending this
    structure.
  * pname:function is the CUDA-Driver handle to the function being launched.
  * pname:gridDimX is the number of local workgroups to dispatch in the X
    dimension.
    It must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[0]
  * pname:gridDimY is the number of local workgroups to dispatch in the Y
    dimension.
    It must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[1]
  * pname:gridDimZ is the number of local workgroups to dispatch in the Z
    dimension.
    It must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[2]
  * pname:blockDimX is block size in the X dimension.
  * pname:blockDimY is block size in the Y dimension.
  * pname:blockDimZ is block size in the Z dimension.
  * pname:sharedMemBytes is the dynamic shared-memory size per thread block
    in bytes.
  * pname:paramCount is the length of the pname:pParams table.
  * pname:pParams is a pointer to an array of pname:paramCount pointers,
    corresponding to the arguments of pname:function.
  * pname:extraCount is reserved for future use.
  * pname:pExtras is reserved for future use.

Kernel parameters of pname:function are specified via pname:pParams, very
much the same way as described in
link:++https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html#group__CUDA__EXEC_1gb8f3dc3031b40da29d5f9a7139e52e15++[cuLaunchKernel]

If pname:function has N parameters, then pname:pParams must: be an array of
N pointers and pname:paramCount must: be N. Each of pname:kernelParams[0]
through pname:kernelParams[N-1] must: point to a region of memory from which
the actual kernel parameter will be copied.
The number of kernel parameters and their offsets and sizes are not
specified here as that information is stored in the slink:VkCudaFunctionNV
object.

The application-owned memory pointed to by pname:pParams and
pname:kernelParams[0] through pname:kernelParams[N-1] are consumed
immediately, and may: be altered or freed after
flink:vkCmdCudaLaunchKernelNV has returned.

.Valid Usage
****
  * [[VUID-VkCudaLaunchInfoNV-gridDimX-09406]]
    pname:gridDimX must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[0]
  * [[VUID-VkCudaLaunchInfoNV-gridDimY-09407]]
    pname:gridDimY must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[1]
  * [[VUID-VkCudaLaunchInfoNV-gridDimZ-09408]]
    pname:gridDimZ must: be less than or equal to
    sname:VkPhysicalDeviceLimits::pname:maxComputeWorkGroupCount[2]
  * [[VUID-VkCudaLaunchInfoNV-paramCount-09409]]
    pname:paramCount must: be the total amount of parameters listed in the
    pname:pParams table
  * [[VUID-VkCudaLaunchInfoNV-pParams-09410]]
    pname:pParams must: be a pointer to a table of pname:paramCount
    parameters, corresponding to the arguments of pname:function
  * [[VUID-VkCudaLaunchInfoNV-extraCount-09411]]
    pname:extraCount must: be 0
  * [[VUID-VkCudaLaunchInfoNV-pExtras-09412]]
    pname:pExtras must: be NULL
****

include::{generated}/validity/structs/VkCudaLaunchInfoNV.adoc[]
--


[[cudadispatch_sharing_resources]]
=== Resource Sharing from Vulkan to the CUDA Kernel

Given that one key limitation of this extension is that Vulkan cannot:
access, nor bind any global resource of CUDA modules, the only way to
exchange data with the kernel must: be to __pass resources via the arguments
of the function__.

ifdef::VK_KHR_buffer_device_address[]
You can use apiext:VK_KHR_buffer_device_address to write/read to/from a
slink:VkBuffer object.
apiext:VK_KHR_buffer_device_address allows you to get the device address of
the buffer to pass it as an argument into pname:pParams.
Application-side pointer arithmetic on the device address is legal, but will
not be bounds-checked on the device.

The corresponding argument of the CUDA function should: be declared as a
pointer of the same type as the referenced buffer.
CUDA code may: simply read or write to this buffer in the typical C way.

endif::VK_KHR_buffer_device_address[]

ifdef::VK_NVX_image_view_handle[]
You may: also use apiext:VK_NVX_image_view_handle as another convenient way
to read/write from/to a slink:VkImage.

The corresponding argument of the CUDA function must: be typed as
`cudaSurfaceObject_t`.

  * You may: read from it by using CUDA surface-read functions such as
    `surf3Dread`, `surf2Dread`, and `surf1Dread`
  * You may: write to it by using CUDA surface-write functions such as
    `surf3Dwrite`, `surf2Dwrite`, and `surf1Dwrite`

Please refer to CUDA
link:https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html%23surface-object-api-appendix[surface
object] documentation for more details

On Vulkan side, here is an example on how to setup
slink:VkImageViewHandleInfoNVX to query the handle for
`cudaSurfaceObject_t`:

[source,c++]
----
VkImageViewHandleInfoNVX imageViewHandleInfo = {VK_STRUCTURE_TYPE_IMAGE_VIEW_HANDLE_INFO_NVX};
imageViewHandleInfo.sampler = VK_NULL_HANDLE;
imageViewHandleInfo.descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE;
imageViewHandleInfo.imageView = imageViewIn; // the VkImageView we want to access
uint32_t myViewHandleIn = vkGetImageViewHandleNVX(m_device, &imageViewHandleInfo);
imageViewHandleInfo.imageView = imageViewOut; // the VkImageView we want to access
uint32_t myViewHandleOut = vkGetImageViewHandleNVX(m_device, &imageViewHandleInfo);
----

Here is an example of how to declare parameters for pname:pParams

[source,c++]
----
VkCudaLaunchInfoNV launchInfo = { VK_STRUCTURE_TYPE_CUDA_LAUNCH_INFO_NV };

int block_size = 8;
float dt = 1.0f / 60.0f;

const void* params[] =
{
  &dt,
  &uint32_t myViewHandleIn,
  &uint32_t myViewHandleOut
};

launchInfo.function = cudaFunction; // CUDA function previously created
launchInfo.gridDimX = (volumeTexDimensionNonBoundary / block_size);
launchInfo.gridDimY = (volumeTexDimensionNonBoundary / block_size);
launchInfo.gridDimZ = (volumeTexDimensionNonBoundary / block_size);
launchInfo.blockDimX = block_size;
launchInfo.blockDimY = block_size;
launchInfo.blockDimZ = block_size;
launchInfo.sharedMemBytes = 0;
launchInfo.paramCount = 3;
launchInfo.pParams = &params[0];
launchInfo.extraCount = 0;
launchInfo.pExtras = nullptr;

vkCmdCudaLaunchKernelNV(commandBuffer, &launchInfo);
----

In the CUDA kernel source code, here is an example on how arguments match
pname:pParams and how we can use Surface object:

[source,c++]
----
extern "C"  __global__ void cudaFunction(
  float dt,
  cudaSurfaceObject_t volumeTexIn,
  cudaSurfaceObject_t volumeTexOut
  )
{
  int i = 1 + blockIdx.x * blockDim.x + threadIdx.x;
  int j = 1 + blockIdx.y * blockDim.y + threadIdx.y;
  int k = 1 + blockIdx.z * blockDim.z + threadIdx.z;

  float val;
  surf3Dread(&val, volumeTexIn, i * sizeof(float), j, k);
  ...
  float result = ...;
  // write result
  surf3Dwrite(result, volumeTexOut, i * sizeof(float), j, k);
}
----

endif::VK_NVX_image_view_handle[]
endif::VK_NV_cuda_kernel_launch[]
